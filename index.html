<!doctype html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Skyler Seto Personal Website</title>
    
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Skyler Seto</h1>
        <p>ss3349 [at] cornell [dot] edu</p>
        <p class="view"><a href="http://github.com/orderedlist/modernist">View the Project on GitHub <small>orderedlist/modernist</small></a></p>
        <ul>
          <li><a href="files/website_resume.pdf">Download <strong>Resume</strong></a></li>
          <li><a href="https://www.linkedin.com/pub/skyler-seto/38/789/309">Connect On  <strong>LinkedIn</strong></a></li>
          <li><a href="https://github.com/skyler120">View On  <strong>GitHub</strong></a></li>
        </ul>
      </header>

    <section>




      <h2>Hello World!</h2>

      <p>My name is Skyler Seto and I'm a Machine Learning researcher at Apple.  Previously I received my P.H.D. from the Department of Statistics and Data Science at Cornell University in 2020 under the supervision of Martin T. Wells, Andrew Wilson, and Thorsten Joachims. I also received my master's degree in Computer Science from Cornell. I graduated from MIT in 2014 with a degree in Mathematics with Computer Science.</p>

      <p>My research interests are at the intersections of adaptive and conditional computation, model compression, and model fairness and robustness.  I work on developing models and algorithms that adaptively use model compute and data to better generalize based on inherent data difficulty. </p>

      <p>My previous industry experiences include internships and work with researchers at Amazon Alexa and Riot Games, and I have done academic work in collaboration with Huawei and Toyota. </p>

      <h2>Research Projects</h2>

      <p> I have/had an active role in the development and release of the following projects: </p>

      <TABLE>
        <TR>
          <TD>Project</TD>
          <TD><center> Abstract (Click for full abstract)  </center> </TD>


        </TR> 

        <TR>
          <TD> <a href="https://arxiv.org/pdf/2203.10117.pdf"> Towards a Perceptual Model for Estimating the Quality of Visual Speech </a> </TD>
          <TD>  

          <span id="showHidLip"> Generating realistic lip motions to simulate speech production is key for driving natural character animations from audio. Previous research has shown that traditional metrics used to optimize and assess models for generating lip motions from speech are not a good indicator of subjective opinion of animation quality.   </span>
          <div id="foLip" style="display:block"></div>

          <script>
            document.getElementById("showHidLip").onclick = function() {
                var theDiv = document.getElementById("foLip");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = 'Generating realistic lip motions to simulate speech production is key for driving natural character animations from audio. Previous research has shown that traditional metrics used to optimize and assess models for generating lip motions from speech are not a good indicator of subjective opinion of animation quality.  ';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = 'Generating realistic lip motions to simulate speech production is key for driving natural character animations from audio. Previous research has shown that traditional metrics used to optimize and assess models for generating lip motions from speech are not a good indicator of subjective opinion of animation quality. Yet, running repetitive subjective studies for assessing the quality of animations can be time-consuming and difficult to replicate. In this work, we seek to understand the relationship between perturbed lip motion and subjective opinion of lip motion quality. Specifically, we adjust the degree of articulation for lip motion sequences and run a user-study to examine how this adjustment impacts the perceived quality of lip motion. We then train a model using the scores collected from our user-study to automatically predict the subjective quality of an animated sequence. Our results show that (1) users score lip motions with slight over-articulation the highest in terms of perceptual quality; (2) under-articulation had a more detrimental effect on perceived quality of lip motion compared to the effect of over-articulation; and (3) we can automatically estimate the subjective perceptual score for a given lip motion sequences with low error rates.     <br> <strong> With Zak Aldeneh, Masha Fedzechkina, Katherine Metcalf, Miguel Sarabia, Nicholas Apostoloff, and Barry-John Theobald </strong> </br>';
                }
            }
          </script>

        </TD>
       </TR>

       </TR> 

        <TR>
          <TD> <a href="https://arxiv.org/pdf/2202.01719.pdf"> FORML: Learning to Reweight Data for Fairness </a> </TD>
          <TD>  

          <span id="showHidFORM"> Deployed machine learning models are evaluated by multiple metrics beyond accuracy, such as fairness and robustness. However, such models are typically trained to minimize the average loss for a single metric, which is typically a proxy for accuracy.   </span>
          <div id="foFORM" style="display:block"></div>

          <script>
            document.getElementById("showHidFORM").onclick = function() {
                var theDiv = document.getElementById("foFORM");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = 'GDeployed machine learning models are evaluated by multiple metrics beyond accuracy, such as fairness and robustness. However, such models are typically trained to minimize the average loss for a single metric, which is typically a proxy for accuracy.  ';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = 'Deployed machine learning models are evaluated by multiple metrics beyond accuracy, such as fairness and robustness. However, such models are typically trained to minimize the average loss for a single metric, which is typically a proxy for accuracy. Training to optimize a single metric leaves these models prone to fairness violations, especially when the population of sub-groups in the training data are imbalanced. This work addresses the challenge of jointly optimizing fairness and predictive performance in the multi-class classification setting by introducing Fairness Optimized Reweighting via Meta-Learning (FORML), a training algorithm that balances fairness constraints and accuracy by jointly optimizing training sample weights and a neural networks parameters. The approach increases fairness by learning to weight each training datums contribution to the loss according to its impact on reducing fairness violations, balancing the contributions from both over- and under-represented sub-groups. We empirically validate FORML on a range of benchmark and real-world classification datasets and show that our approach improves equality of opportunity fairness criteria over existing state-of-the-art reweighting methods by approximately 1% on image classification tasks and by approximately 5% on a face attribute prediction task. This improvement is achieved without pre-processing data or post-processing model outputs, without learning an additional weighting function, and while maintaining accuracy on the original predictive metric.    <br> <strong> With Bobby Yan, and Nicholas Apostoloff</strong> </br>';
                }
            }
          </script>

        </TD>
       </TR>

        <TR>
          <TD> <a href="https://epubs.siam.org/doi/pdf/10.1137/1.9781611976700.63"> HALO: Learning to Prune Neural Networks with Shrinkage </a> </TD>
          <TD>  

          <span id="showHidHALO"> Deep neural networks achieve state-of-the-art performance in a variety of tasks by extracting a rich set of features from unstructured data, however this performance is closely tied to model size. </span>
          <div id="foHALO" style="display:block"></div>

          <script>
            document.getElementById("showHidHALO").onclick = function() {
                var theDiv = document.getElementById("foHALO");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = 'Deep neural networks achieve state-of-the-art performance in a variety of tasks by extracting a rich set of features from unstructured data, however this performance is closely tied to model size.';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = 'Deep neural networks achieve state-of-the-art performance in a variety of tasks by extracting a rich set of features from unstructured data, however this performance is closely tied to model size. Modern techniques for inducing sparsity and reducing model size are (1) network pruning, (2) training with a sparsity inducing penalty, and (3) training a binary mask jointly with the weights of the network. We study these approaches from the perspective of Bayesian hierarchical models and present a novel penalty called Hierarchical Adaptive Lasso (HALO) which learns to sparsify weights of a given network via trainable parameters. When used to train over-parametrized networks, our penalty yields small subnetworks with high accuracy without fine-tuning. Empirically, on image recognition tasks, we find that HALO is able to learn highly sparse network (only 5% of the parameters) with significant gains in performance over state-of-the-art magnitude pruning methods at the same level of sparsity. Code and appendix are available at the provided links.   <br> <strong> With Martin T. Wells, and Wenyu Zhang</strong> </br> <strong> SIAM International Conference on Data Mining </strong>';
                }
            }
          </script>

        </TD>
       </TR>


        <TR>
          <TD> <a href="https://arxiv.org/pdf/2003.11696.pdf"> CAZSL: Zero-Shot Regression for Pushing Models by Generalizing Through Context </a> </TD>
          <TD>  

          <span id="showHideCAZSL"> Learning accurate models of the physical world is required for a lot of robotic manipulation tasks. However, during manipulation, robots are expected to interact with un-known workpieces so that building predictive models which can generalize over a number of these objects is highly desirable. </span>
          <div id="foCAZSL" style="display:block"></div>

          <script>
            document.getElementById("showHideCAZSL").onclick = function() {
                var theDiv = document.getElementById("foCAZSL");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = 'Learning accurate models of the physical world is required for a lot of robotic manipulation tasks. However, during manipulation, robots are expected to interact with un-known workpieces so that building predictive models which can generalize over a number of these objects is highly desirable.';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = 'Learning accurate models of the physical world is required for a lot of robotic manipulation tasks. However, during manipulation, robots are expected to interact with un-known workpieces so that building predictive models which can generalize over a number of these objects is highly desirable. In this paper, we study the problem of designing deep learning agents which can generalize their models of the physical world by building context-aware learning models. The purpose of these agents is to quickly adapt and/or generalize their notion of physics of interaction in the real world based on certain features about the interacting objects that provide different contexts to the predictive models. With this motivation, we present context-aware zero shot learning (CAZSL, pronounced as casual) models, an approach utilizing a Siamese network architecture, embedding space masking and regularization based on context variables which allows us to learn a model that can generalize to different parameters or features of the interacting objects. We test our proposed learning algorithm on the recently released Omnipush datatset that allows testing of meta-learning capabilities using low-dimensional data. Codes for CAZSL are available at https://www.merl.com/research/license/CAZSL.   <br> <strong> With Wenyu Zhang, and Devesh K. Jha</strong> </br> <strong> Presented at the 2015 NIPS Symposium on Interpretable Machine Learning </strong>';
                }
            }
          </script>

        </TD>
       </TR>

        <TR>
          <TD> <a href="https://openreview.net/pdf?id=rJgjYyaio7"> Exponential Family Word Embeddings </a> </TD>
          <TD>  

          <span id="showHidWE"> GloVe and Skip-gram word embedding methods learn word vectors by decomposing a denoised matrix of word co-occurrences into a product of low-rank matrices. In this work, we propose an iterative algorithm for computing word vectors based on modeling word co-occurrence matrices with Generalized Low Rank Models. </span>
          <div id="foWE" style="display:block"></div>

          <script>
            document.getElementById("showHidWE").onclick = function() {
                var theDiv = document.getElementById("foWE");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = 'GloVe and Skip-gram word embedding methods learn word vectors by decomposing a denoised matrix of word co-occurrences into a product of low-rank matrices. In this work, we propose an iterative algorithm for computing word vectors based on modeling word co-occurrence matrices with Generalized Low Rank Models.';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = 'GloVe and Skip-gram word embedding methods learn word vectors by decomposing a denoised matrix of word co-occurrences into a product of low-rank matrices. In this work, we propose an iterative algorithm for computing word vectors based on modeling word co-occurrence matrices with Generalized Low Rank Models. Our algorithm generalizes both Skip-gram and GloVe as well as giving rise to other embedding methods based on the specified co-occurrence matrix, distribution of co-occurences, and the number of iterations in the iterative algorithm. For example, using a Tweedie distribution with one iteration results in GloVe and using a Multinomial distribution with full-convergence mode results in Skip-gram. Experimental results demonstrate that multiple iterations of our algorithm improves results over the GloVe method on the Google word analogy similarity task.   <br> <strong> With Ben Baer, and Martin T. Wells</strong> </br> <strong> Presented at the 2018 NIPS IRASL Workshop';
                }
            }
          </script>

        </TD>
       </TR>


       <TR>
          <TD> <a href="https://arxiv.org/abs/1711.07104"> A Double Parametric Bootstrap Test for Topic Models </a> </TD>
          <TD>  

          <span id="showHidDPBS"> Non-negative matrix factorization (NMF) is a technique for finding latent representations of data.</span>
          <div id="fo1" style="display:block"></div>

          <script>
            document.getElementById("showHidDPBS").onclick = function() {
                var theDiv = document.getElementById("fo1");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = 'Non-negative matrix factorization (NMF) is a technique for finding latent representations of data.';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = 'Non-negative matrix factorization (NMF) is a technique for finding latent representations of data. The method has been applied to corpora to construct topic models. However, NMF has likelihood assumptions which are often violated by real document corpora. We present a double parametric bootstrap test for evaluating the fit of an NMF-based topic model based on the duality of the KL divergence and Poisson maximum likelihood estimation. The test correctly identifies whether a topic model based on an NMF approach yields reliable results in simulated and real data. <br> <strong> With Sarah Tan, Giler Hooker, and Martin T. Wells</strong> </br> <strong> Presented at the 2017 NIPS Symposium on Interpretable Machine Learning </strong> <a href="files/poster-double-parametric.pdf">Poster Presentation</a>';
                }
            }
          </script>

        </TD>
       </TR>

        <TR>
          <TD> <a href="https://dspace.mit.edu/handle/1721.1/106392"> Car Trip Destination Prediction </a> </TD>
          <TD>  
          
          <span id="showHide"> This research develops an automated data science pipeline for organizing and condensing large database formats into event-driven time series data for machine learning prediction. </span>
          <div id="foo" style="display:block"></div>

          <script>
            document.getElementById("showHide").onclick = function() {
                var theDiv = document.getElementById("foo");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = 'This research develops an automated data science pipeline for organizing and condensing large database formats into event-driven time series data for machine learning prediction.';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = 'This research develops an automated data science pipeline for organizing and condensing large database formats into event-driven time series data for machine learning prediction.   Using this framework, a large collection of automobile trip data is organized and 3.8 million prediction problems are generated from a mixture of different car signals (such as time, GPS, temperature, radio, etc.) and analyzed. <br>  <strong> With Jason Wu and Kalyan Veeramachanini</strong> <br /> <strong> Work to appear in Model Factory: A New Way to Look at Data Through Models (Yonglin Wu, M.E. thesis Section 4.1.1 and Appendix A) </strong> ';
                }
            }
          </script>

        </TD>
       </TR>

       <TR>
          <TD><a href="http://arxiv.org/abs/1512.06747"> Human Activity Recognition </a></TD>
          <TD> 
          <span id="showHide2"> Accurate and computationally efficient means for classifying human activities have been the subject of extensive research efforts.</span>
          <div id="foo2" style="display:block"></div>

          <script>
            document.getElementById("showHide2").onclick = function() {
                var theDiv = document.getElementById("foo2");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = 'Accurate and computationally efficient means for classifying human activities have been the subject of extensive research efforts.';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = '  Accurate and computationally efficient means for classifying human activities have been the subject of extensive research efforts.  Most current research focuses on extracting complex features to achieve high classification accuracy. This research proposes a template selection approach based on Dynamic Time Warping, such that complex feature extraction and domain knowledge is avoided. The predictive capability of the algorithm is demonstrated to exceed conventional methods in many aspects.  <br /> <strong> With Wenyu Zhang, and Yichen Zhou </strong> <br /> <strong> In Proceedings of the 2015 Symposium Series on Computational Intelligence </strong>';
                }
            }
          </script>
          </TD>
       </TR>

       <TR>
          <TD><a href="files/RIPS.pdf">Maximum Likelihood Detection in MIMO Systems</a></TD>
          <TD> 
          <span id="showHide3"> A typical channel communication signal transmission and reception process mainly consists of five stages: encoding, modulation, channel, demodulation and decoding.</span>
          <div id="foo3" style="display:block"></div>

          <script>
            document.getElementById("showHide3").onclick = function() {
                var theDiv = document.getElementById("foo3");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = 'A typical channel communication signal transmission and reception process mainly consists of five stages: encoding, modulation, channel, demodulation and decoding.';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = '  A typical channel communication signal transmission and reception process mainly consists of five stages: encoding, modulation, channel, demodulation and decoding.  Equalization is the process of recovering the original signal from the received, noisy signal during the demodulation stage. This process can be difficult especially for low powered signals.  Modifying existing equalization algorithms, two new equalization algorithms are developed with comparable accuracy and efficiency.  <br /> <strong> With Karen Larson, Albert Ku, Lauren Luo, and Fisher Yu </strong> <br /> <strong> Presented at the 2013 Joint Mathematics Meetings </strong>';
                }
            }
          </script>
          </TD>
       </TR>

       <TR>
          <TD><a href="files/Xiaotao_Skyler_poster.pdf">Bioinformatics Analysis of HDAC-Interacting Proteins</a></TD>
          <TD> 
          <span id="showHide4"> Many proteins that have previously been described as protein modification enzymes represent only single members of protein complexes and only function properly together with other factors.</span>
          <div id="foo4" style="display:block"></div>

          <script>
            document.getElementById("showHide4").onclick = function() {
                var theDiv = document.getElementById("foo4");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = 'Many proteins that have previously been described as protein modification enzymes represent only single members of protein complexes and only function properly together with other factors.';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = '  Many proteins that have previously been described as protein modification enzymes represent only single members of protein complexes and only function properly together with other factors.  Using publicly available databases and bioinformatics tools such as BLAST, putative interacting proteins of eighteen human HDACs were identified by constructing a “round trip” between human HDACs and their interacting proteins through homologues in other species that are experimentally verified to interact.  Results not only confirmed many HDAC-interacting proteins previously identified by biochemical and cell biology methods, but also suggested hundreds of potential HDAC-interacting partners that escaped conventional methods of detection. <br /> <strong> With Xiaotao Qu </strong> <br /> <strong> Presented at the American Society for Cell Biology 49th Annual Meeting </strong>';
                }
            }
          </script>
          </TD>
       </TR>

      </TABLE>


      <h2>Side Projects</h2>

      <p> Additionally, I have contributed to smaller "fun" projects outside of research. I've linked a few of my favorites:

      <TABLE>
        <TR>
          <TD>Project</TD>
          <TD><center> Summary (Click for full summary) </center> </TD>


        </TR> 

        <TR>
          <TD><a href="files/LA Presentation.pdf">GradeExplorer</a></TD>


          <TD> 


          <span id="showHide0"> The central idea of this work is predicting the distribution of student total scores (raw percentages) at the end of the semester.</span>
          <div id="foo0" style="display:block"></div>

          <script>
            document.getElementById("showHide0").onclick = function() {
                var theDiv = document.getElementById("foo0");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = 'The central idea of this work is predicting the distribution of student total scores (raw percentages) at the end of the semester.';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = '  The central idea of this work is predicting the distribution of student total scores (raw percentages) at the end of the semester. We design an algorithm that finds for each student the probability his/her total score will be within some range given his/her available assignment scores, and historical data from prior iterations of the course. A web visualization is also created to help students view their performance relative to peers.<br /> <strong> With Wenyu Zhang, Anton Gilgur, and Erik Andersen </strong> <br /> <strong> Presentation to the Cornell Learning Analytics Group </strong>';
                }
            }
          </script>



          </TD>

       </TR>

        <TR>
          <TD><a href="files/6742_presentation.pdf"> Caring on Reddit</a> </TD>
          <TD> 
          <span id="showHide1"> Online communities are open to users worldwide, and large websites attract millions of users, but not all of the users keep active in these communities.</span>
          <div id="foo1" style="display:block"></div>

          <script>
            document.getElementById("showHide1").onclick = function() {
                var theDiv = document.getElementById("foo1");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = 'Online communities are open to users worldwide, and large websites attract millions of users, but not all of the users keep active in these communities.';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = 'Online communities are open to users worldwide, and large websites attract millions of users, but not all of the users keep active in these communities.  In this study, Reddit users are  aggregated into two group, loyalists and vagrants, by their activity level, and linguistic differences are demonstrated between the two.  Through  simple activity indicators, such as word counts, coarse language models, and finer-grained word-level examination, we discover that the two types of users have different focuses and carry different roles in the online communities.  <br /> <strong> With Justine Zhang, Tianze Shi, Lillian Lee, and Cristian Danescu-Niculescu-Mizil </strong>';
                }
            }
          </script>

       </TR>

        <TR>
          <TD><a href="files/18.821 Paper 2.pdf">Dynamical Systems with Polygons</a></TD>


          <TD> 


          <span id="showHide5"> 18.821 Project List Problem Statement</span>
          <div id="foo5" style="display:block"></div>

          <script>
            document.getElementById("showHide5").onclick = function() {
                var theDiv = document.getElementById("foo5");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = '18.821 Project List Problem Statement';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = '  <strong> 18.821 Project List Problem Statement: </strong> Consider a square, with a natural number at each endpoint. At the midpoint of each edge, write the absolute value |a − b| of the difference (a, b),  the numbers at the endpoints of each edge. Draw a smaller square connecting those midpoints, and repeat. The game stops if you get to (0, 0, 0, 0).  What are the lenghts of these games? What can one say about the maximum length of a game given initial bounds on the numbers at each endpoint?  In this paper, we solve this initial problem as well as other extensions. <br /> <strong> With Eli Ross, and Chae Won Lee </strong>';
                }
            }
          </script>



          </TD>

       </TR>


       <TR>
          <TD><a href="http://ocw.mit.edu/ans7870/CMS/CMS.611/F13/AquaticEvolver.swf">Aquatic Evolver</a></TD>


          <TD> 


          <span id="showHide6"> In Aquatic Evolver, players guide an amoeba-like creature through an aquatic environment.</span>
          <div id="foo6" style="display:block"></div>

          <script>
            document.getElementById("showHide6").onclick = function() {
                var theDiv = document.getElementById("foo6");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = 'In Aquatic Evolver, players guide an amoeba-like creature through an aquatic environment.';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = '  In Aquatic Evolver, players guide an amoeba-like creature through an aquatic environment.  Players begin with a body and tentacle, and gain different appendages by fighting other amoeba-like creatures and evolving.  As players progress through the depths monsters get increasingly aggressive and powerful.  How far into the depths will you make it? <br /> <strong> With Marcel Polanco, Nick Benson, Allen Park, Carlo Beidenharn, Jancarlo Perez, Jan Rodriguez, Pedro Cattori, Rohan Mahajan, Justin White, and Travis Wagner </strong>';
                }
            }
          </script>



          </TD>

       </TR>


       <TR>
          <TD><a href="http://apark93.mit.edu/cardblocks/final/cardblocks/">Card Blocks (Prototype)</a></TD>


          <TD> 


          <span id="showHide7"> Card Blocks is a tetris-like puzzle video game in which players form blocks of numbers to earn points and fight their opponent.</span>
          <div id="foo7" style="display:block"></div>

          <script>
            document.getElementById("showHide7").onclick = function() {
                var theDiv = document.getElementById("foo7");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = 'Card Blocks is a tetris-like puzzle video game in which players form blocks of numbers to earn points and fight their opponent.';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = 'Card Blocks is a tetris-like puzzle video game in which players form blocks of numbers to earn points and fight their opponent.  Each Card is a number from 1-9. Blocks are sets of two or more cards with the same number or sets of three or more consecutive numbers aligned horizontally or vertically.   Once a block is formed, it immediately dissapears and reappears on the enemy\'s board in a random location.  Each block earns points.  You will win if you have the most points at the end of five minutes or if you can fill your opponent\'s board.  <br /> <strong> With Allen Park, Nathan Pinsker </strong>';
                }
            }
          </script>


          </TD>


       </TR>


       <TR>
          <TD><a href="http://6.270.scripts.mit.edu/"> LEGO Robotics Competition </a></TD>



          <TD> 


          <span id="showHide8"> 6.270 is a MIT class/competition where competitors design a fully autonomous LEGO robot to compete by navigating...</span>
          <div id="foo8" style="display:block"></div>

          <script>
            document.getElementById("showHide8").onclick = function() {
                var theDiv = document.getElementById("foo8");
                if(theDiv.style.display == 'none') {
                    theDiv.style.display = 'block';
                    this.innerHTML = '6.270 is a MIT class/competition where competitors design a fully autonomous LEGO robot to compete by navigating...';
                } else {
                    theDiv.style.display = 'none';
                    this.innerHTML = '6.270 is a MIT class/competition where competitors design a fully autonomous LEGO robot to compete by navigating around a surface, recognizing enemy robots, manipulating game objects such as balls and gear boxes, and surviving three foot drop tests.  My team (Team 24 - Yoyac) placed second at the <a href= "http://webcast.amps.ms.mit.edu/i/institute/2012-2013/6.270/"> 2013 competition</a>.  <br /> <strong> With Jason Yang, and Sayeed Tasnim </strong>';
                }
            }
          </script>


          </TD>


       </TR>





      </TABLE>



    </section>  


    </div>  
    <footer>
      <p>Project maintained by <a href="https://github.com/skyler120">Skyler Seto</a></p>
      <p>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></p>
    </footer>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
